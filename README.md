# ğŸ§  RAPTOR on PubMedQA (Healthcare Dataset)

This repository implements a **RAPTOR (Recursive Abstractive Processing
for Tree-Organized Retrieval)** pipeline on the **PubMedQA** public
healthcare dataset.

The system:

-   Builds a hierarchical semantic tree over a medical document\
-   Uses UMAP + Gaussian Mixture Models (GMM) for clustering\
-   Generates LLM-based summaries at each tree level\
-   Performs Collapsed Tree Retrieval (retrieving from leaf + summary
    nodes)\
-   Answers 1--2 queries using a HuggingFace-hosted LLM

------------------------------------------------------------------------

## ğŸ“Œ What is RAPTOR?

RAPTOR is a hierarchical retrieval method that:

1.  Splits a document into chunks\
2.  Embeds them using sentence transformers\
3.  Clusters semantically similar chunks\
4.  Summarizes each cluster using an LLM\
5.  Recursively builds higher-level summaries\
6.  Retrieves context from both raw text and summaries

This enables better long-document reasoning and multi-level semantic
abstraction.

------------------------------------------------------------------------

## ğŸ¥ Dataset

**PubMedQA (pqa_labeled split)**\
A public biomedical question answering dataset containing:

-   Research context passages\
-   Long answers\
-   Final decision labels (yes / no / maybe)

Loaded via:

``` python
load_dataset("pubmed_qa", "pqa_labeled", split="train")
```

------------------------------------------------------------------------

## ğŸ—ï¸ System Architecture

Document\
â†“\
Sentence-aware Chunking\
â†“\
Embeddings (multi-qa-mpnet-base-cos-v1)\
â†“\
UMAP Dimensionality Reduction\
â†“\
GMM Clustering (BIC-selected)\
â†“\
LLM Summaries (recursive)\
â†“\
Hierarchical Tree\
â†“\
Collapsed Tree Retrieval\
â†“\
LLM Answer Generation

------------------------------------------------------------------------

## âš™ï¸ Installation

Install required dependencies:

``` bash
pip install datasets sentence-transformers umap-learn scikit-learn faiss-cpu huggingface_hub
```

------------------------------------------------------------------------

## ğŸ” HuggingFace Token (Colab Secret)

This project uses a hidden HuggingFace token via Google Colab secrets.

### In Google Colab:

1.  Click ğŸ”‘ Secrets (left sidebar)\
2.  Add key: `HF_TOKEN`\
3.  Paste your HuggingFace token\
4.  Enable notebook access

The code loads it securely using:

``` python
from google.colab import userdata
HF_TOKEN = userdata.get("HF_TOKEN")
```

âš ï¸ The token is never hardcoded.

------------------------------------------------------------------------

## ğŸš€ Running the Project

``` python
run_raptor_pubmedqa_single_example(
    example_idx=0,
    queries=None,
    chunk_tokens=100,
    max_levels=3,
    top_k=12,
    max_context_tokens=900,
)
```

### What it does:

-   Loads one PubMedQA example\
-   Builds a RAPTOR tree\
-   Runs 1--2 queries\
-   Retrieves hierarchical context\
-   Generates an LLM answer

------------------------------------------------------------------------

## ğŸ“ˆ Why RAPTOR?

  Feature                   RAG   RAPTOR
  ------------------------- ----- --------
  Flat retrieval            âœ…    âŒ
  Hierarchical reasoning    âŒ    âœ…
  Cluster summarization     âŒ    âœ…
  Multi-level abstraction   âŒ    âœ…
  Better long-doc QA        âš ï¸    âœ…

------------------------------------------------------------------------

## ğŸ“š References

-   RAPTOR Paper: Recursive Abstractive Processing for Tree-Organized
    Retrieval\
-   PubMedQA Dataset\
-   Sentence Transformers\
-   UMAP\
-   FAISS

------------------------------------------------------------------------

## ğŸ‘¨â€ğŸ’» Author

Abhishek Prithvi Teja Angadala\
AI / ML / LLM Systems
